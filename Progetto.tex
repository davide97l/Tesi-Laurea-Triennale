\section{Progettazione}
\epigraph{Little by little, we're giving sight to the machines. First, we teach them to see. Then, they help us to see better.}{\textit{Li Fei Fei}}
\subsection{Progettazione algoritmo per riconoscimento di elementi in un'immagine frammentata}
Per quanto riguarda il problema della frammentazione dei frames in 4K è stato individuato un apposito algoritmo in grado di effettuare il riconoscimento degli oggetti nei frames presenti in un video senza doverli ridimensionare ma utilizzando la tecnica della frammentazione dell'immagine.
\subsubsection{Scomposizione del frame originale in regioni}
Un frame in 4K viene quindi scomposto in una matrice di R x C sotto-immagini chiamate regioni\gls in modo tale che ogni regione sia efficacemente analizzabile da un modello come Faster R-CNN senza perdita di risoluzione. Per facilitare l'operazione di riconoscimento degli elementi da parte della rete, ogni regione può essere leggermente sovrapposta con le sue regioni adiacenti. Per definire la quantità di pixels da coinvolgere nella sovrapposizione viene definito uno stride\gls che indica quanti pixels della regione tralasciare, sia in verticale che in orizzontale, prima che cominci quella successiva, ovviamente lo stride deve essere minore della larghezza di una regione.
Una Faster R-CNN dopo aver elaborato singolarmente ogni regione come se fosse una singola immagine darà in output una lista di labels con le seguenti caratteristiche:
\begin{itemize}
\item \textbf{(max-x, max-y)}: coordinate del vertice in alto a sinistra del rettangolo rappresentante il bounding box dell'oggetto riconosciuto; 
\item \textbf{(min-x, min-y)}: coordinate del vertice in basso a destra del rettangolo rappresentante il bounding box dell'oggetto riconosciuto; 
\item \textbf{Categoria}: è un numero naturale che indica la categoria di appartenenza dell'elemento individuato;
\item \textbf{Score}: rappresenta la misura di probabilità che la classificazione ottenuta sia effettivamente quella corretta.
\end{itemize}
Successivamente viene aggiustata la posizione delle labels individuate in modo da traslarle nella loro posizione corretta all'interno dell'immagine originale non frammentata. Questo viene fatto aggiungendo un adeguato offset alle coordinate dei vertici dei bounding boxes delle labels sulla base della loro regione di appartenenza.
\subsubsection{Rimozione degli elementi individuati più volte all'interno delle aree di sovrapposizione}
A causa della presenza delle aree di sovrapposizione dovute alla struttura delle regioni, gli elementi giacenti in queste particolari zone del frame verranno individuati tante volte quante sono le regioni che si sovrappongono in quella determinata area. Per eliminare le copie duplicate e tenerne solo una viene utilizzato un algoritmo chiamato Average Non-Max Suppression (ANMS) che è una variante del Non-Max Suppression tipicamente utilizzato dai modelli di visione artificiale. Per ogni gruppo di labels sovrapposte, invece che tenere la label con lo score maggiore ed eliminare tutte le altre, il nuovo bounding box viene calcolato come la media dei bouding boxes box di tutte labels e lo score viene calcolato come la media tra tutti gli scores.
Questo metodo è fondato sul ragionamento che non bisognerebbe buttare via delle informazioni già possedute ma piuttosto riutilizzarle per scoprire qualcosa di nuovo. Per esempio ad uno stesso elemento visualizzato dentro due sezioni differenti di un' immagine potrebbero venirgli assegnati due score diversi. Mentre NMS conserverebbe solo il valore più alto tra i due, ANMS li utilizzerebbe entrambi per ottenere un valore ancora più affidabile aumentando quindi la veridicità della classificazione. Per tutto il resto del documento la sigla NMS intenderà la sua versione ANMS.
\subsubsection{Creazione di raggruppamenti di labels correlate} 
A questo punto tutti gli elementi sono stati individuati e classificati ma rimane comunque il problema che, a causa della precedente scomposizione, gli oggetti situati all'interno o in prossimità delle aree di sovrapposizione risulterebbero individuati due o più volte. Come si può vedere in figura 6, questo numero varia in base al numero di regioni sulle quali giace l'oggetto. Il secondo problema è che due elementi \textit{vicini} \footnote{Due labels sono considerate vicine se sono intersecate tra di loro ed intersecano lo stesso confine di regione}, anche se classificati nella stessa categoria, non è detto che necessariamente debbano rappresentare lo stesso elemento. Un esempio di questo caso lo si può sempre notare in figura 6. Un caso ancora peggiore lo si ha quando non solo l'elemento è situato su più regioni differenti ma sussiste anche il problema che ogni parte dell'elemento verrebbe classificata in modo diverso a causa della loro ambiguità. Infine, è anche possibile che un oggetto si distribuisca su più regioni adiacenti ed ogni sua label presenti dimensioni o categorie diverse per ogni regione.
\begin{figure}
\begin{center}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-1.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-4.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-6.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-5.jpg}
\end{center}
\caption{Esempi di labels erroneamente individuate a causa della frammentazione e relativa corretta ricostruzione}
\end{figure}
La soluzione individuata consiste nel raggruppare labels correlate tra loro in insiemi di labels dette raggruppamenti\gls per poi racchiuderli in una label che identifica l'elemento rappresentato dal raggruppamento. Due labels sono in correlazione tra di loro se soddisfano una condizione di correlazione sotto riportata.\\
\textbf{Condizione di correlazione}: Per effettuare un corretto raggruppamento delle labels viene anche tenuta in considerazione la categoria a loro associata tramite la classificazione insieme allo score assegnato. Per definire il risultato della condizione è inoltre necessario stabilire una \textbf{soglia di affidabilità}\gls che indica lo score minimo che una label deve possedere per poter considerare la sua classificazione come affidabile o meno. Di seguito vengono riportati i vari casi per decidere se la condizione è vera o falsa.
\begin{itemize}
\item \textbf{True}: Le due labels hanno la stessa categoria ed entrambe con score uguale o maggiore della soglia;
\item \textbf{True}: Le due labels hanno la stessa categoria ma almeno una delle due ha score minore della soglia;
\item \textbf{True}: Le due labels hanno categoria diversa ma almeno una delle due ha score minore della soglia;
\item \textbf{False}: Le due labels hanno categoria diversa ed entrambe con score uguale o maggiore della soglia;
\end{itemize}
Prima di cominciare con il raggruppamento, vengono inizialmente individuate tutte le labels che intersecano i confini di regioni causati dalle aree di sovrapposizione o che non distino più di un fissato numero di pixels, detto \textbf{overlap}\gls, da esse. L'overlap viene definito in quanto anche se nell'immagine reale un oggetto interseca un confine di regione è possibile che a causa di errori di imprecisione del modello, il box della label risulti leggermente distaccato dalla linea che rappresenta il confine. E' quindi possibile ovviare a questo problema aumentando lo spessore del confine di tanti pixels quanti indicati dall'overlap.
Per lo stesso motivo precedente, ai fini di controllare se una label interseca un' altra entità o meno viene anche tenuta in considerazione una \textbf{tolleranza}\gls che indica di quanto il bounding box di una label può essere distante da un'entità affinché questa venga comunque considerata come intersecata.
Per creare i raggruppamenti di labels è stato ideato il seguente algoritmo:
\begin{enumerate}
\item Vengono tenute solo le labels che intersecano almeno un confine di regione e vengono inizializzate come \textit{non controllate} e \textit{non raggruppate};
\item Viene selezionata una label qualsiasi \textit{non controllata} e la si imposta come \textit{controllata};
\item Per ogni label \textit{controllata} ma non ancora \textit{raggruppata} controlla se ci sono altre labels \textit{non controllate} che rispettino ognuna delle seguenti condizioni:
  \begin{itemize}
  \item Devono essere \textit{vicine} o distanti entro la tolleranza fissata;
  \item Devono rispettare la \textit{condizione di correlazione};
  \item La loro box non deve intersecare una regione al di fuori delle aree di sovrapposizione che sia già intersecata da una qualsiasi altra label \textit{controllata}\footnote{Questo perché se due labels sono state individuate come elementi distinti all'interno di una regione allora è probabile che lo siano anche nell'immagine intera in quanto viene supposto che un modello non commetta errori di riconoscimento};
  \item Deve essere rispettata una \textbf{soglia di matching}\gls: La posizione delle loro bounding boxes deve essere compatibile entro una certa soglia, ovvero che, i lati lungo il quale le due labels vengono unite siano tali che la differenza tra quello maggiore e quello minore sia inferiore ad una certa soglia che può essere sia definita come una proporzione rispetto ad uno dei due lati oppure come un valore in pixels.
  \end{itemize}  
\item Le labels così trovate diventano a loro volta \textit{controllate};
\item Si ripetono i punti 3 e 4 fino a che non sia più possibile trovare ulteriori labels;
\item Tutte le label \textit{controllate} vengono ora classificate come \textit{raggruppate} e viene assegnato un numero progressivo ad ogni label \textit{raggruppata} in modo da identificarne il gruppo di appartenenza;
\item Si ripetono i punti da 2 a 6 fino a che tutte le labels non vengano raggruppate. L'algoritmo in questo modo termina sempre ed è possibile che un raggruppamento comprenda una sola label.
\end{enumerate}
E' da notare che labels intersecanti ma interamente comprese in una sola regione non sono motivo di interesse in quanto l'algoritmo di NMS utilizzato dalla rete in fase di post-processing ci assicura che labels intersecanti nella stessa regione individuino elementi diversi.
In seguito bisogna trasformare ogni raggruppamento in una nuova label che racchiuda tutte le labels che lo compongono. Per fare questo vengono esaminate le coordinate di ogni vertice di tutte le bounding boxes di un raggruppamento in modo tale da trovare quattro nuovi vertici di un rettangolo che soddisfi i requisiti sopra discussi. La nuova label così creata andrà a sostituire le labels del rispettivo raggruppamento e per deciderne la categoria e lo score viene applicata una \textbf{regola di classificazione}: categoria e score assegnati saranno pari alla categoria e allo score posseduti dalla label con score maggiore appartenente al raggruppamento.\\
A questo punto l'algoritmo può dirsi concluso ed è in grado di riconoscere gli elementi in un'immagine anche in 4K con un'accuratezza accettabile e buona velocità. Tuttavia in casi particolari come quello mostrato in figura 7 l'algoritmo commetterebbe un errore di classificazione in quanto individuerebbe due elementi distinti con una sola label comune. In questi casi non c'è modo di sapere se le due labels effettivamente appartengono a due oggetti distinti o se rappresentano lo stesso oggetto. In realtà impostando correttamente la \textbf{soglia di matching} si potrebbe ricostruire correttamente queste labels ma tale soglia, impostata ad un valore molto alto, potrebbe far fallire la ricostruzione di molte più labels portando quindi ad un peggioramento generale delle metriche di valutazione. 
\begin{figure}
\begin{center}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-2.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-3.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-8.jpg}
\includegraphics[width=0.2\textwidth, height=0.25\textheight]{images/esempio-frammentazione-7.jpg}
\end{center}
\caption{Esempi di labels erroneamente individuate a causa della frammentazione e relativa errata ricostruzione}
\end{figure}
\subsubsection{Miglioramento: raggruppamenti di labels utilizzati come region proposal}
Un ulteriore miglioramento dell'algoritmo potrebbe essere ottenuto utilizzando le labels ottenute dal procedimento descritto in precedenza come nuove regioni sulle quali applicare nuovamente una detection per identificare gli elementi contenuti nella regione ma con maggiore precisione in quanto questa volta l'area non verrà affetta da problemi di frammentazione dando quindi la possibilità alla rete di esaminare l'area per intero. La regione viene prima inizializzata rimuovendo la sua label e poi ripopolata con le nuove labels identificate dalla rete.\\
Il primo problema che salta fuori è che durante questo procedimento la rete identificherà nuovamente anche quegli elementi che casualmente si trovavano dentro la regione coinvolta ma che erano già stati trovati anche in precedenza. Tuttavia questo problema viene tranquillamente risolto applicando un algoritmo di average non-max suppression, utilizzato già in precedenza, per eliminare gli oggetti quasi completamente sovrapposti.\\
Il secondo problema riguarda ancora gli oggetti che stanno a cavallo tra la regione interessata e l'immagine originale, questa volta però, avendoli già individuati nella loro interezza durante la prima fase è quindi solamente necessario unire la nuova label con quella già trovata in precedenza in modo da ottenerne una nuova con precisione maggiore.\\
Un caso particolare lo si ha quando la la regione in esame risulti essere così estesa da vanificare i vantaggi ottenuti dalla frammentazione. Per far fronte a questo problema basta ridimensionare l'area coinvolta fino a portarla ad avere dimensioni gestibili da una rete. In questo caso la perdita di risoluzione e quindi di dettagli non comporterebbe un grave problema in quanto gli elementi visibili solo grazie all'alta definizione sarebbero già stati individuati nella fase precedente. Nel caso in cui questi oggetti dovessero venire nuovamente identificati verrebbero gestiti dall'ANMS per ottenerne una migliore approssimazione. Questa funzionalità permette di migliorare l'accuratezza quando si vogliono identificare oggetti che si estendono su due o più regioni o per migliorare il riconoscimento di gruppi di elementi sovrapposti e molto vicini tra loro in prossimità di un confine dove il precedente algoritmo potrebbe commettere un errore nel loro riconoscimento come mostrato in figura 7.
\subsection{Progettazione algoritmo per tracciamento di elementi}
Per affrontare il problema del tracciamento degli elementi, viene utilizzato un algoritmo di tracking supportato da una detection applicata ad ogni frame del video al fine di garantirne una migliore accuratezza\cite{trackingdetection}. L'algoritmo è indipendente dalle dimensioni dei frames del video ma se necessario è comunque possibile effettuare la detection utilizzando l'algoritmo descritto in sezione \textit{4.1} in modo da non ridurre la qualità dei frames.
\subsubsection{Filtro di Kalman}
Lo scopo di un tracker è quello di predire la posizione di un oggetto in un frame a partire dallo storico delle sue locazioni passate per mezzo di un filtro. I trackers implementati utilizzano un filtro di Kalman\cite{kalman} in quanto esso si rivela molto efficace nell'effettuare predizioni anche in sistemi soggetti a continui cambiamenti come lo è per esempio un video. Il secondo vantaggio è quello di garantire una buona resistenza contro i rumori causati da detections imprecise, le quali possono per esempio avere luogo in presenza di oggetti parzialmente occultati o deformati a causa di qualche spostamento. Infine, questa tipologia di filtri sono anche computazionalmente veloci in quanto, una volta implementati, la loro esecuzione si traduce in semplici moltiplicazioni tra matrici.\\
L'applicazione del filtro di Kalman consiste in due fasi distinte: predizione ed aggiornamento. La prima fase ha come scopo quello di usare la locazione precedente per predire quella attuale effettuando anche una piccola correzione per far fronte alle variazioni introdotte da possibili fonti esterne (rumore). In seguito sono riportate le formule relative alla fase di predizione:
\[
    x\ped{k} = F\ped{k}x\ped{k-1} + B\ped{k}u\ped{k}
\]
\[
    P\ped{k} = F\ped{k}P\ped{k-1}F\ped{k}\ap{T} + Q\ped{k}
\]
Dove x\ped{k} è la predizione della posizione dell'oggetto \textit{x} nel frame \textit{k}, F\ped{k} è il modello di transizione di stato applicato alla posizione x\ped{k-1}, B\ped{k} è una matrice di controllo alla quale viene applicato il vettore di controllo u\ped{k} e rappresentano le variazioni subite da x\ped{k} causate da una fonte esterna, in questo caso rappresentano movimenti irregolari dell'oggetto rispetto alla sua traiettoria. P\ped{k} è la predizione della covarianza di x\ped{k} mentre Q\ped{k} è la covarianza del processo che genera rumore.\\
Nella seconda fase, quella di aggiornamento, viene usata la misurazione corrente, che in questo caso sarà il bounding box dell'oggetto tracciato individuato dalla nuova detection, per rifinire ulteriormente la sua locazione esatta. In seguito sono riportate le formule relative alla fase di aggiornamento:
\[
    x\ped{k}\ap{'} = x\ped{k} + K(z\ped{k}-H\ped{k}x\ped{k})
\]
\[
    P\ped{k}\ap{'} = P\ped{k} - KH\ped{k}P\ped{k}
\]
\[
	K = P\ped{k}H\ped{k}\ap{T}(H\ped{k}P\ped{k}H\ped{k}\ap{T} + R\ped{k})\ap{-1}
\]
Dove x\ped{k}\ap{'} è la nuova stima della posizione ottenuta dopo aver effettuato l'aggiornamento, K è una matrice detta anche guadagno di Kalman, z\ped{k} è il valore misurato, in questo caso corrisponderà alla label individuata con la detection effettuata sul frame k. H\ped{k} è una matrice che serve per scalare z\ped{k} in modo tale da renderlo compatibile con lo stato dell'oggetto tracciato ed infine R\ped{k} è la covarianza di z\ped{k}.\\ Riassumendo, lo scopo del filtro di Kalman è quello di individuare la posizione reale di un oggetto mettendo insieme due informazioni distinte: una è la predizione della sua locazione rispetto alla sua posizione precedente e l'altra è la sua posizione individuata con una detection tenendo però conto che essa può essere soggetta ad imprecisioni.
\subsubsection{Assegnazione detection-tracker}
Il passo successivo è quello di abbinare ognuno dei bounding box stimati dai filtri dei trackers con le bounding boxes individuate da una detection.\\
Questo risultato viene ottenuto tramite un algoritmo di ottimizzazione conosciuto anche come algoritmo di Munkres\cite{hungarian}. La metrica utilizzata dall'algoritmo è l'IoU tra i bounding boxes stimati dai trackers durante la fase di predizione dei loro filtri e quelli individuati dalla detection, tale metrica viene spiegata in dettaglio nella sezione \textit{7.1.3}.\\ L'obiettivo dell'algoritmo è quello di assegnare le detections ai trackers massimizzando la somma dell'IoU delle bounding boxes associate. Questa soluzione si basa sul ragionamento che più due bounding boxes sono sovrapposte, più è probabile che esse rappresentino lo stesso oggetto. Inoltre, perchè due bounding boxes possano essere associate, il loro IoU deve anche essere maggiore o uguale di una certa soglia, detta \textbf{soglia di assegnazione}\gls in quanto tra due boxes poco sovrapposte è probabile che non vi sia alcuna correlazione.\\
Il primo passo dell'algoritmo consiste nel creare una matrice di dimensioni \textit{n} x \textit{m} dove \textit{n} è il numero di oggetti individuati dalla detection ed \textit{m} è il numero di trackers. Se le colonne dovessero essere minori delle righe allora bisogna ruotare la matrice in modo tale che le colonne siano tante almeno quante sono le righe e tenere in considerazione questa eventuale rotazione per ottenere il risultato finale.\\
In ogni cella della matrice viene calcolato il valore dell'IoU tra la box predetta dal tracker \textit{i} ed il box \textit{j} individuato dalla detection, con 1\textless = \textit{i}\textless =m e 1\textless =\textit{i}\textless =n.
In seguito vengono ripetuti i seguenti passi:
\begin{enumerate}
\item Per ogni riga, sottrarre il valore minimo della riga a tutti gli elementi della stessa riga. In questo modo, in ogni riga sarà presente almeno una cella con valore pari a 0.
\item Per ogni colonna, sottrarre il valore minimo della colonna a tutti gli elementi della stessa colonna. In questo modo, in ogni colonna sarà presente almeno una cella con valore pari a 0.
\item Tracciare delle linee attraverso tutte le righe e le colonne che contengano almeno un elemento pari a 0 in modo tale da tracciare il minor numero di linee possibile.
\item Se sono state tracciate esattamente \textit{k}=min(\textit{n},\textit{m}) allora l'algoritmo termina qui, altrimenti si procederà con il passo 5.
\item Trova la cella minore che non sia tracciata da alcuna linea e poi sottrarre quel valore a tutte le righe non tracciate, sommare poi quel valore ad ogni colonna tracciata. Infine tornare al passo 3.
\end{enumerate} 
Al termine dell'algoritmo si selezionano \textit{k}=min(\textit{n},\textit{m}) zeri dalle celle della matrice tali che ogni zero appartenga ad una sola riga e ad una sola colonna. Le coordinate di queste celle corrisponderanno agli assegnamenti tracker-detection ottimali da attuare nella matrice originale.
\begin{figure}[H]
	\centering
	\includegraphics[width=0.7\linewidth]{images/detection-tracker-assignment.png}
	\caption{Esempio di assegnazione detection-tracker}
	\label{Esempio di assegnazione detection-tracker}
\end{figure}
Come si può vedere in figura 8 i rettangoli rossi raffigurano le bounding boxes dei trackers mentre quelle verdi rappresentano le bounding boxes individuate dalla detection. I trackers 1 e 2 vengono assegnati regolarmente mentre l'elemento tracciato dal tracker 3 è sparito dal frame ed è comparso un nuovo elemento che verrà tracciato da un nuovo tracker.
\subsubsection{Gestione delle detections e dei trackers non assegnati}
Nel caso in cui nella matrice precedente si abbia avuto che \textit{n} è diverso da \textit{m}, significa che sono presenti dei trackers o delle detections che non sono state assegnate. Inoltre, le coppie tracker-detection associate con successo dall'algoritmo il quale IoU sia però inferiore alla soglia stabilita verranno scartate ed aggiunte nelle rispettive liste di trackers e detections non assegnate.\\
La mancata assegnazione di un tracker al suo elemento potrebbe avere due cause scatenanti: la prima è che l'oggetto tracciato sia momentaneamente sparito dal video a causa di una detection non andata a buon fine. Questo evento può essere per esempio dovuto ad una momentanea perdita di qualità di un frame, da un occultamento o da una sfocatura causata da un movimento.\\
La seconda causa è che l'oggetto sia effettivamente assente in un frame del video a causa di un suo movimento verso l'esterno del frame oppure a causa di un cambio di inquadratura. In questo caso è poco probabile che l'oggetto scomparso ritorni a presentarsi nel frame successivo ma è più ragionevole pensare che esso non si ripresenterà più, almeno nel breve periodo.\\
In quanto un tracker non ha modo di sapere quale delle due cause sia quella che abbia realmente portato alla sua mancata assegnazione, allora in presenza di questo evento viene solamente incrementato un contatore interno al tracker che tiene conto dei frames consecutivi trascorsi senza che il tracker venga associato al suo oggetto tracciato. Non appena questo contatore supera una certa soglia, detta \textbf{soglia di cancellazione}\gls, il relativo tracker viene cancellato e l'elemento da esso tracciato viene considerato come perduto. Se un elemento perduto dovesse successivamente ricomparire in un frame esso verrà considerato come un nuovo oggetto venendo quindi tracciato da un nuovo tracker.\\
Un discorso analogo vale anche per quelle labels che sono individuate da una detection ma che non vengono assegnate a nessuno dei trackers già esistenti. Con molta probabilità si tratta di una nuovo oggetto ed è quindi opportuno creare un nuovo tracker per iniziare a tracciarlo. Tuttavia, prima che il legame tracker-detection diventi effettivo non basta che l'assegnazione avvenga una sola volta. Potrebbe infatti accadere che a causa di una detection sbagliata, un oggetto di una determinata categoria compaia erroneamente in un solo frame per poi non ripresentarsi più. In questo caso sfortunato si verrebbe a creare un tracker la cui utilità sarebbe poco significativa consumando un ID per essere associato ad un oggetto individuato per errore.\\
Per risolvere questo problema ogni tracker implementa un altro contatore per tenere traccia dei frames consecutivi nei quali al tracker stesso viene assegnato un oggetto, questo contatore rappresenta quindi la durata in frames del tracciamento. Solamente dopo che questo contatore abbia superato una certa soglia, detta \textbf{soglia di validazione}\gls, verrà assegnato un ID al tracker e la sua corrispondente bounding box verrà mostrata nel video.\\
Una volta terminata questa fase, vengono utilizzate le nuove detections per aggiornare i filtri dei trackers e rifinire la stima della locazione degli oggetti tracciati (fase di aggiornamento).
\subsubsection{Utilizzo di metriche di supporto per l'assegnazione detection-tracker}
Durante il processo di assegnazione tracker-detection viene utilizzata solamente l'IoU per calcolare la metrica per decidere come abbinare le varie bounding boxes presenti in un frame. Questa metrica verrà anche chiamata come \textbf{valore di matching}\gls tra due bounding boxes e più questo valore è alto, maggiore è la possibilità che due bounding boxes, una predetta dal filtro di un tracker e l'altra individuata da una detection, vengano associate.\\
Tuttavia, in presenza di sovrapposizioni, il valore di matching, facendo affidamento solo sull'IoU, potrebbe non risultare abbastanza affidabile. Pensiamo per esempio al caso in cui due persone A e B che, camminando in direzioni opposte, incrocino brevemente la loro traiettoria. In un determinato frame è possibile che, essendo le bounding boxes delle due persone molto sovrapposte sovrapposte, venga commesso un errore nell'assegnazione tracker-detection causando quindi uno scambio di ID tra le due persone. Da quel frame in poi la persona A verrà quindi tracciata con l'ID B e viceversa.\\
Per ridurre la probabilità che questo sfortunato evento accada, la metrica utilizzata per determinare il valore di matching tra le bounding boxes di una detection e un tracker non sarà soltanto l'IoU tra le loro aree ma possono venire aggiunte anche altre metriche di supporto come il rapporto tra la dimensione delle loro aree ed il rapporto tra le dimensioni dei loro lati\cite{hybridboost}. Questo ragionamento si basa sul fatto che tra due frames consecutivi, queste metriche normalmente non possono subire una grande variazione rispetto allo stesso oggetto e quindi possono essere utili nell'effettuare un'eventuale associazione qualora affidarsi all sola IoU non risulterebbe molto efficace. Ovviamente, possono anche essere definiti dei pesi per rendere ciascuna metrica più importante o meno. 